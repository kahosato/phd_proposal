\documentclass[11pt]{article}
\title{Research Proposal}
\author{
 Kaho Sato\\
  \texttt{ks789@cam.ac.uk}
}
\usepackage[round]{natbib}
\usepackage{enumitem}

\begin{document}
\maketitle
As internationalisation progresses at a rapid rate, there is a high global interest in learning English, arguably the current lingua franca of the world. Application of Natural Language Processing (NLP) techniques to create systems that automatically assess learners' writing in English has been an active field of research, with the aim of making language learning more accessible. In particular, there have been many works on automatic grammatical error detection and correction in texts produced by non-native speakers of English~\citep{izumi2003automatic, eeg2003automatic, han2006detecting, tetreault2008ups, de2008classifier, gamon2008using, gamon2010using, ng2014conll}. Especially for learners with low proficiency in English, grammatical errors are one of the primary problems that need to be tackled, thus automating detection and correction has a great impact in learning. Grammatical error detection and correction are not only useful for the educational purpose, but also can be used to improve writing assistance systems which are typically incorporated in word processors like Microsoft Word. Catering to the need of non-native speakers who outnumber native speakers by a ratio of 3 to 1 is commercially beneficial, therefore has been stirring up high interest in this particular sub-field of NLP. In the following, I explicitly discuss grammatical error detection and correction in text produced by \emph{non-native speakers}, whom I will refer to as ``authors''.

Specifically, I would like to investigate how the knowledge of authors' first language (L1) could improve error detection and correction in their texts written in their second language (L2). \cite{lado1957linguistics} suggested \emph{Contrastive Analysis Hypothesis} which states that the difference between one's L1 and L2 determines the difficulty in acquiring L2 and the errors they make in L2. This is based on the observation that, when using a L2, one often applies knowledge from their L1; this phenomenon is often referred to as L1 transfer~\citep{wanner1982language, frenck1997syntactic, dussias2003syntactic, nitschke2010first}. Though this interference may result in a grammatically sound output, it may as well leads to errors. For instance, an Italian speaker may say ``*I have 20 years'' instead of ``I am 20 years old'', as it is the direct translation of the equivalent expression in Italian. Though not all the errors made in L2 can be described by L1 transfer, knowing which errors are likely to occur due to L1 transfer should improve error detection and correction.

As stated previously, much work has been done in automatic grammatical error detection and correction. Errors which have been explored the most are article errors~\citep{han2006detecting, rozovskaya2010training, turner2007language, dahlmeier2011grammatical, de2008classifier} and preposition errors~\citep{bergsma2009web, tetreault2008ups, tetreault2010using, dahlmeier2011grammatical, de2008classifier, chodorow2007detection}. This is hardly surprising, as they are the most frequent error types and their confusion sets are finite since they are closed-class, which makes the error detection and correction essentially an n-class classification problem. These errors were the main focus of the 2012 HOO Shared Task~\citep{dale2012hoo} and 14 teams have presented a system that detects and corrects them.

Collocation errors are also well-studied~\citep{shei2000esl, wible2003bootstrapping, futagi2008computational, liu2009automated}, though to a lesser extent. This is possibly due to its complexity; the size of confusion sets is almost infinite. It therefore requires identify potentially ambiguous triggers first, and then determining the type of mistake made and correcting it. In other words, error correction and detection are two separate tasks when we consider open class words errors.

It has been shown that the knowledge on authors' L1 improves algorithms that detect and correct errors in the use of prepositions or articles~\citep{rozovskaya2010generating, rozovskaya2011algorithm}. There have also been similar works for errors in the use of open-class words~\citep{chang2008automatic, dahlmeier2011correcting, shei2000esl, liu2009automated}. However, I believe that there is still much room for investigation on how authors' L1 can be used for the errors in the use of open-class words for two reasons. Firstly, out of many types of errors one can make with open-class words, most works focus on verb-noun collocation errors~\citep{chang2008automatic, shei2000esl, liu2009automated}. Other errors such as verb form errors or other types of collocation errors are yet to be explored. Secondly, most of the works on errors with open-class words focus on correction of them~\citep{dahlmeier2011correcting, chang2008automatic} and there has been little work on L1-specific detection of errors with open-class words.  In my research, I would like to carry out a thorough investigation on this very promising, yet underexplored area.

The partial reason why there is not many work that takes authors' L1 into consideration is that not in all situation their L1 is known. For instance, shared tasks that focuses on grammatical error detection and corrections such as the HOO shared tasks and the CoNLL shared tasks do not reveal the authors' L1 and it is not likely that word processors such as Microsoft Word would know L1 of the user. In my MPhil project, I would like to investigate whether a pipeline of L1 identification algorithm and error correction algorithm outperforms systems that does not use authors' L1. If it does, it makes a very strong case for the use of L1 in error detection and correction. The L1 identification task has been investigated by various research \citep{estival2007author, tomokiyo2001you, koppel2005determining, koppel2005automatically, wong2009contrastive, kochmar2011identification}. However, as far as I am aware, there is no work that connects an L1 identification and error correction algorithms. Clearly, the performance of such a pipeline highly depends on the accuracy of the L1 identification algorithm and I plan to build on and improve the previous works. Only a part of the L1s that can be observed in Cambridge Learner Corpus is covered by the existing works. For instance, \cite{kochmar2011identification} focuses on distinguishing texts written by five Romance languages (Italian, Catalan, Spanish, Portuguese and French) and five Germanic languages (German, Swiss German, Dutch, Swedish and Danish). Cambridge Learner Corpus contains scripts by students speaking over 130 different L1. Though it is certainly beyond the scope of an MPhil project to cover more L1, let alone all L1, in PhD I would like to device L1 identification algorithm that can distinguish all L1 language groups.

The errors I would like to investigate are the following.
\begin{enumerate}
\item Errors in collocation beyond verb-noun combination \label{error:1}
\item Verb form errors \label{error:2}
\item Spelling Errors \label{error:3}
\end{enumerate}

For collocation errors, I would like to extend the approach presented in the work by \cite{kochmarcross} which is distinct for two reasons. Firstly, it is an algorithm for detection, rather than correction, of errors in verb-noun collocation errors. Secondly, rather than using L1-specific properties, such as the error patterns of speakers of a given L1, it utilises a semantic model of L1 and L2. These semantic models are built from corpus statistics in each language independently and errors of lexical choice is done using the discrepancies between the two models. The results are promising, and it also shows that the semantic model learned from a particular L1 is portable to other, typologically related languages. This approach was applied to texts produced by Spanish and Russian native speakers. I would like to further investigate whether this algorithm can be used to detect other types of errors in texts produced by not only Spanish or Russian speakers, but also other L1 speakers on which data is available in the Cambridge Learner Corpus.
					
Most works in collocation error correction have relied on dictionaries or manually created databases~\citep{shei2000esl, wible2003bootstrapping, futagi2008computational}. Dictionaries suffer from low coverage and does not provide probability estimate for each candidate translation, and manually creating databases is expensive and not scalable. I would like to investigate more data-driven methods, taking advantage of the Cambridge Learner Corpus. For instance, I plan to investigate whether the confusion matrix for a particular L1 estimated from the actual learner corpus can be used for collocation errors of arbitrary syntactic types.

A subset of verb form errors that require little contextual information has been investigated well, such as improper user of modals (\emph{they can *built/build a new house}) and overregularised verb inflection (*goed/went)~\citep{chodorow2000unsupervised, leacock2003automated}. These errors are handled well by simple rule-based approaches and they are rarely result of L1 transfer, but simply of author's lack of L1 knowledge. The verb form error that I would like to tackle is verb tense errors. Tenses largely vary from a language to another. For instance, Chinese is a tenseless language in which the temporal information is conveyed by words that accompany the verb and Italian has finer distinctions in the past tense than English. It is expected that there is a difference in the error pattern between authors of different L1 and therefore L1 could be a useful clue in identifying this type of errors. Verb tense errors are more challenging to detect because tenses are influenced by factors that are not local to the sentence. For example, ``I have a plate of pasta'' alone is a perfectly grammatical sentence. However when combined with another sentence in past tense, like in ``I had a great dinner last night. I *have a plate of pasta.'', it is most likely not in the tense that the author intended. \cite{tajiri2012tense} regarded this problem as a sequence labelling task, where each member is the verb that appear in the document. The set of features that describe a verb includes namely its part-of-speech tag, its arguments such as subject and object. I would like to augment the model with the authors' L1 and train it on Cambridge Learner Corpus and see whether the performance improves. It would also be interesting to make an empirical study of the error pattern of authors with respect to their L1. The outcome of such study can potentially be used to extend the work by \cite{lee2008correcting}. In this work, errors are detected by template matching on parse trees. The templates are created from parse trees that represents a sentence to which they introduced a likely error that a non-native speaker would make. Since the sentence is ungrammatical, the parsed tree should look different from those of grammatical sentences. Since the errors which an author is likely to make partially depend on their L1, we could create different templates for each L1 using the error patterns found in the empirical study.

Spelling errors can be committed by both native and non-native speakers. Task of detecting and correcting spelling errors has been extensively studied for much longer time than any other errors~\citep{heift2007errors}. However, the majority of the work investigates errors made by native speakers. Spelling errors made by non-native speakers are very different from those made by native speakers. The former tend to be multiple edit distance away from the intended word, where the latter tend to have single edit distance. Consequently, many spelling checkers perform terribly on non-native speakers texts. Indeed, \cite{rimrott2005language} demonstrates that only 48\% of spelling errors in German texts produced by non-native speakers were corrected by Microsoft Word 2003 spelling checker, which are configured to catch native speakers' spelling errors.  \cite{rimrott2008evaluating} claims that spelling errors made by non-native speakers can be classified into three categories which are lexical, morphological and phonological errors. Lexical errors are errors that are made because of the author simply did not know the word in L2. This is often easy to detect as it often results to a non-word spelling error. Morphological errors are characterised by incorrect inflection. For instance, one may not know that ``go'' is a irregular verb and write ``goed'', overgeneralising the morphological rules. This type of errors is not made due to L1 transfer, but should be attributed to the author's lack of the knowledge. Phonological errors are caused by the actual or assumed phonology. For instance, a Japanese person may spell ``libraly", because ``l'' and ``r'' are not distinct phonemes in Japanese unlike in English. One may take a completely statistical approach to detect phonological errors. However, the data might be very sparse. It might be better to extract a common phonological error patterns from Cambridge Learner Corpus and create heuristic rules from them.

\cite{kochmarcross} use heuristics that L1 transfer in typologically related languages results in similar errors. This is certainly an approximation; Italian and Spanish are both Romance languages. However, Italian speakers often say ``*I like your hairs'' instead of ``I like your hair'', whereas Spanish speakers are less inclined to make this particular error. Conversely, speakers of languages in different families may commit similar mistakes. Misuse of articles is common both for Polish and Japanese speakers, as neither of these two languages have this grammatical construct. I would like to explore how languages could be grouped for each error type, and investigate whether it can improve error detection and correction.

It is not realistic to aim to cover all the errors which were discussed. In the first year, I would like to focus on extending L1 identification algorithm to cover all L1 language groups of first languages of the authors of the texts in Cambridge Learner Corpus. Then I would like to have a thorough investigation on collocation errors of arbitrary syntactic types by the end of the first year.

L1 transfer is undeniably the source of many errors made by non-native speakers. Previous works have shown that L1 of the learner can improve error correction in texts produced by language learners. I would like to build on these works, namely by investigating other types of errors, making the algorithm more data-driven, extending it to error correction and using finer grained grouping of L1 languages. 



(2271 words)



\bibliography{bib}
\bibliographystyle{plainnat}
\end{document}
